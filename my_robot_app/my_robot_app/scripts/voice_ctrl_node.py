#!/usr/bin/env python3
"""
ç¦»çº¿è¯­éŸ³æ§åˆ¶èŠ‚ç‚¹
ä½¿ç”¨Voskè¿›è¡Œæœ¬åœ°è¯­éŸ³è¯†åˆ«
"""

import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import threading
import time
import json
import os
import pyaudio
import numpy as np
from vosk import Model, KaldiRecognizer
import re

class VoiceControlNode(Node):
    def __init__(self):
        super().__init__('voice_control_node')
        
        # å‚æ•°å£°æ˜
        self.declare_parameter('model_path', '~/vosk-model-small-cn-0.22')
        self.declare_parameter('sample_rate', 16000)
        self.declare_parameter('energy_threshold', 0.01)
        self.declare_parameter('min_silence_duration', 1.0)
        
        # è·å–å‚æ•°
        self.sample_rate = self.get_parameter('sample_rate').value
        self.energy_threshold = self.get_parameter('energy_threshold').value
        self.min_silence_duration = self.get_parameter('min_silence_duration').value
        model_path = os.path.expanduser(self.get_parameter('model_path').value)
        
        # å‘å¸ƒè€…
        self.command_pub = self.create_publisher(String, '/voice_control', 10)
        self.speech_pub = self.create_publisher(String, '/speech_text', 10)
        
        # åˆå§‹åŒ–Voskæ¨¡å‹
        self.get_logger().info("ç¦»çº¿è¯­éŸ³æ§åˆ¶èŠ‚ç‚¹åˆå§‹åŒ–...")
        
        try:
            self.get_logger().info(f"åŠ è½½Voskæ¨¡å‹: {model_path}")
            if not os.path.exists(model_path):
                self.get_logger().error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                self.get_logger().info("è¯·ä¸‹è½½ä¸­æ–‡æ¨¡å‹: wget https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip")
                raise FileNotFoundError(f"Voskæ¨¡å‹æœªæ‰¾åˆ°: {model_path}")
            
            self.model = Model(model_path)
            self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
            self.get_logger().info("âœ… Voskæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            self.get_logger().error(f"æ— æ³•åŠ è½½Voskæ¨¡å‹: {e}")
            raise
        
        # éŸ³é¢‘ç³»ç»Ÿåˆå§‹åŒ–
        self.audio = pyaudio.PyAudio()
        self.stream = None
        
        # æ§åˆ¶æ ‡å¿—
        self.is_active = False
        self.recognition_thread = None
        self.silence_threshold_frames = int(self.min_silence_duration * self.sample_rate / 4000)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.recognition_count = 0
        self.last_command_time = 0
        self.command_cooldown = 1.0
        
        # å‘½ä»¤æ˜ å°„è¡¨ï¼ˆä¸é¡¹ç›®å…¶ä»–éƒ¨åˆ†ä¿æŒä¸€è‡´ï¼‰
        self.command_map = {
            # ç§»åŠ¨å‘½ä»¤
            'å‰è¿›': 'move_forward',
            'å¾€å‰èµ°': 'move_forward',
            'å‘å‰': 'move_forward',
            'åé€€': 'move_backward',
            'å‘å': 'move_backward',
            'å·¦è½¬': 'turn_left',
            'å‘å·¦è½¬': 'turn_left',
            'å‘å·¦': 'turn_left',
            'å³è½¬': 'turn_right',
            'å‘å³è½¬': 'turn_right',
            'å‘å³': 'turn_right',
            
            # åœæ­¢å‘½ä»¤
            'åœæ­¢': 'stop',
            'åœä¸‹': 'stop',
            'åœ': 'stop',
            'æš‚åœ': 'stop',
            
            # æŠ“å–å‘½ä»¤
            'æŠ“å–': 'pick_object',
            'æŠ“': 'pick_object',
            'æ‹¿': 'pick_object',
            'å–ç‰©': 'pick_object',
            
            # æ”¾ç½®å‘½ä»¤
            'æ”¾ä¸‹': 'place_object',
            'æ”¾ç½®': 'place_object',
            'æ”¾': 'place_object',
            'é‡Šæ”¾': 'place_object',
            
            # å¯¼èˆªå‘½ä»¤
            'å›å®¶': 'go_home',
            'è¿”å›': 'go_home',
            'å›åŸç‚¹': 'go_home',
            'å»èµ·ç‚¹': 'go_home',
        }
        
        # æŸ¥æ‰¾éŸ³é¢‘è®¾å¤‡
        self._find_audio_device()
        
        self.get_logger().info("âœ… ç¦»çº¿è¯­éŸ³è¯†åˆ«å‡†å¤‡å°±ç»ª")
    
    def _find_audio_device(self):
        """æŸ¥æ‰¾åˆé€‚çš„éŸ³é¢‘è®¾å¤‡"""
        device_count = self.audio.get_device_count()
        
        for i in range(device_count):
            try:
                info = self.audio.get_device_info_by_index(i)
                if info['maxInputChannels'] > 0:
                    self.device_index = i
                    self.get_logger().info(f"âœ… ä½¿ç”¨éŸ³é¢‘è®¾å¤‡: {info['name']}")
                    return
            except:
                continue
        
        self.get_logger().error("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡")
        raise Exception("No audio input device found")
    
    def _open_audio_stream(self):
        """æ‰“å¼€éŸ³é¢‘æµ"""
        try:
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                input_device_index=self.device_index,
                frames_per_buffer=int(self.sample_rate * 0.1),
            )
            
            self.get_logger().info(f"âœ… éŸ³é¢‘æµæ‰“å¼€æˆåŠŸ")
            return True
            
        except Exception as e:
            self.get_logger().error(f"âŒ æ— æ³•æ‰“å¼€éŸ³é¢‘æµ: {e}")
            return False
    
    def _calculate_energy(self, audio_data):
        """è®¡ç®—éŸ³é¢‘èƒ½é‡"""
        if len(audio_data) == 0:
            return 0.0
        
        try:
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            if len(audio_array) == 0:
                return 0.0
            
            squared = audio_array.astype(np.float32) ** 2
            mean_squared = np.mean(squared)
            
            if mean_squared <= 0:
                return 0.0
            
            energy = np.sqrt(mean_squared) / 32768.0
            
            return float(energy)
                
        except Exception as e:
            self.get_logger().debug(f"èƒ½é‡è®¡ç®—é”™è¯¯: {e}")
            return 0.0
    
    def start_listening(self):
        """å¼€å§‹ç›‘å¬"""
        if self.is_active:
            self.get_logger().warning("å·²ç»åœ¨ç›‘å¬ä¸­")
            return
        
        # æ‰“å¼€éŸ³é¢‘æµ
        if not self._open_audio_stream():
            self.get_logger().error("æ— æ³•æ‰“å¼€éŸ³é¢‘æµ")
            return
        
        self.is_active = True
        self.recognition_thread = threading.Thread(target=self._listening_loop)
        self.recognition_thread.daemon = True
        self.recognition_thread.start()
        
        self.get_logger().info("ğŸ¤ å¼€å§‹ç¦»çº¿è¯­éŸ³ç›‘å¬...")
    
    def _listening_loop(self):
        """ç›‘å¬å¾ªç¯"""
        try:
            self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
            
            audio_buffer = bytes()
            is_speaking = False
            silence_counter = 0
            chunk_size = 4000
            
            self.get_logger().info("éŸ³é¢‘å¤„ç†å¾ªç¯å¯åŠ¨...")
            
            while self.is_active and self.stream and rclpy.ok():
                try:
                    # è¯»å–éŸ³é¢‘æ•°æ®
                    data = self.stream.read(chunk_size, exception_on_overflow=False)
                    
                    # VADæ£€æµ‹
                    energy = self._calculate_energy(data)
                    has_speech = energy > self.energy_threshold
                    
                    if has_speech:
                        if not is_speaking:
                            self.get_logger().info("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•éŸ³...")
                            is_speaking = True
                            silence_counter = 0
                        
                        audio_buffer += data
                        silence_counter = 0
                            
                    elif is_speaking:
                        silence_counter += 1
                        
                        if silence_counter >= self.silence_threshold_frames:
                            # å¤„ç†å½•éŸ³
                            self.get_logger().info("æ£€æµ‹åˆ°é™éŸ³ï¼Œå¼€å§‹è¯†åˆ«...")
                            self._process_audio_buffer(audio_buffer)
                            
                            # é‡ç½®çŠ¶æ€
                            audio_buffer = bytes()
                            is_speaking = False
                            silence_counter = 0
                            self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
                            
                    else:
                        # æ²¡æœ‰è¯­éŸ³æ—¶ï¼ŒçŸ­æš‚ä¼‘çœ ä»¥é™ä½CPUä½¿ç”¨ç‡
                        time.sleep(0.01)
                    
                except Exception as e:
                    self.get_logger().error(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
                    time.sleep(0.1)
                    
        except Exception as e:
            self.get_logger().error(f"ç›‘å¬å¾ªç¯é”™è¯¯: {e}")
            self.is_active = False
        finally:
            self._close_audio_stream()
    
    def _process_audio_buffer(self, audio_buffer):
        """å¤„ç†éŸ³é¢‘ç¼“å†²åŒº"""
        if not audio_buffer or len(audio_buffer) < 8000:
            self.get_logger().warning("éŸ³é¢‘æ•°æ®å¤ªçŸ­ï¼Œå¿½ç•¥")
            return
        
        try:
            # è¯†åˆ«éŸ³é¢‘
            if self.recognizer.AcceptWaveform(audio_buffer):
                result = json.loads(self.recognizer.Result())
                text = result.get('text', '').strip()
            else:
                result = json.loads(self.recognizer.PartialResult())
                text = result.get('partial', '').strip()
            
            if text:
                self.recognition_count += 1
                self.get_logger().info(f"âœ… è¯†åˆ«ç»“æœ: {text}")
                
                # å‘å¸ƒåŸå§‹è¯­éŸ³æ–‡æœ¬
                speech_msg = String()
                speech_msg.data = text
                self.speech_pub.publish(speech_msg)
                
                # å¤„ç†å‘½ä»¤
                self._process_command(text)
                
        except Exception as e:
            self.get_logger().error(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
    
    def _process_command(self, text):
        """å¤„ç†è¯†åˆ«åˆ°çš„å‘½ä»¤"""
        # æ¸…ç†æ–‡æœ¬
        clean_text = re.sub(r'[ã€‚ï¼Œï¼ï¼Ÿã€,\.!\?]', '', text)
        
        current_time = time.time()
        if current_time - self.last_command_time < self.command_cooldown:
            self.get_logger().warning("å‘½ä»¤å†·å´ä¸­...")
            return False
        
        self.get_logger().info(f"å¤„ç†æ–‡æœ¬: {clean_text}")
        
        # ç²¾ç¡®åŒ¹é…
        for keyword, command in self.command_map.items():
            clean_keyword = re.sub(r'[ã€‚ï¼Œï¼ï¼Ÿã€,\.!\?]', '', keyword)
            
            if clean_keyword == clean_text or clean_keyword in clean_text:
                self._publish_command(command, clean_keyword)
                self.last_command_time = current_time
                return True
        
        self.get_logger().warning(f"æœªè¯†åˆ«çš„å‘½ä»¤: {clean_text}")
        return False
    
    def _publish_command(self, command, keyword):
        """å‘å¸ƒå‘½ä»¤"""
        msg = String()
        msg.data = command
        self.command_pub.publish(msg)
        self.get_logger().info(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {command}")
    
    def _close_audio_stream(self):
        """å…³é—­éŸ³é¢‘æµ"""
        if self.stream:
            try:
                self.stream.stop_stream()
                self.stream.close()
            except:
                pass
            finally:
                self.stream = None
    
    def stop_listening(self):
        """åœæ­¢ç›‘å¬"""
        if self.is_active:
            self.get_logger().info("åœæ­¢è¯­éŸ³ç›‘å¬...")
            self.is_active = False
            
            self._close_audio_stream()
            
            if self.recognition_thread:
                self.recognition_thread.join(timeout=2.0)
    
    def destroy_node(self):
        """æ¸…ç†èµ„æº"""
        self.stop_listening()
        if self.audio:
            self.audio.terminate()
        super().destroy_node()

def main(args=None):
    rclpy.init(args=args)
    node = VoiceControlNode()
    
    try:
        node.get_logger().info("\nğŸ¤ ç¦»çº¿è¯­éŸ³æ§åˆ¶èŠ‚ç‚¹å¯åŠ¨")
        node.get_logger().info("ğŸ’¡ å¸¸ç”¨å‘½ä»¤: 'å‰è¿›', 'åé€€', 'å·¦è½¬', 'å³è½¬', 'åœæ­¢'")
        node.get_logger().info("ğŸ’¡ æ£€æµ‹åˆ°é™éŸ³åè‡ªåŠ¨è¯†åˆ«")
        
        # å¯åŠ¨ç›‘å¬
        node.start_listening()
        
        # ä¸»å¾ªç¯
        rclpy.spin(node)
        
    except KeyboardInterrupt:
        node.get_logger().info("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        node.get_logger().error(f"âŒ ç¨‹åºé”™è¯¯: {e}")
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
